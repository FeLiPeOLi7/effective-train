import pandas as pd
from newsapi import NewsApiClient
from key import my_api_key
from sklearn.feature_extraction.text import CountVectorizer
from sklearn import svm
import re
import unicodedata

class Indicators:
    FEAR = "MEDO"
    FEAR_LIST = ["queda", "crash", "recess칚o", "cair", "morreu", "acabou", "risco", "desvaloriza칞칚o", "p칙nico", "inseguran칞a", "baixa", "desastre", "venda", "bear"]
    GREED = "OTIMISTA"
    GREED_LIST = ["alta", "valoriza칞칚o", "subir", "recorde", "lucro", "crescimento", "oportunidade", "expans칚o", "confian칞a", "compra", "bull"]
    NEUTRAL = "NEUTRO"

def clean_text(text):
    # Remove pontua칞칫es e acentos, transforma em min칰sculas
    text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode('utf-8')
    text = re.sub(r'[^\w\s]', '', text)
    return text.lower()

def label_text(text, greed_list, fear_list):
    greed = 0
    fear = 0
    cleaned_text = clean_text(text)
    for word in cleaned_text.split():
        if word in greed_list:
            greed += 1
        elif word in fear_list:
            fear += 1
    
    if greed > fear:
        return Indicators.GREED
    elif fear > greed:
        return Indicators.FEAR
    else:
        return Indicators.NEUTRAL


def sentiment_analysis(data_frame):
    
    contents = data_frame['content'].fillna('').values.tolist()
    titles = data_frame['title'].fillna('').values.tolist()
    texts = contents + titles #train_x

    # Adiciona manualmente textos com palavras relevantes, pois somente as not칤cias n칚o s칚o suficientes
    texts.extend([
        "O Bitcoin vai explodir em breve, uma grande alta vem a칤",     # OTIMISTA
        "Compre agora antes da valoriza칞칚o",                            # OTIMISTA
        "O mercado est치 em p칙nico com a queda",                         # MEDO
        "Desvaloriza칞칚o forte causa inseguran칞a entre investidores",    # MEDO
        "O Bitcoin morreu", #MEDO
        "O Bitcoin ir치 cair, venda r치pido", #MEDO
    ])

    vectorizer = CountVectorizer()
    train_x_vectors = vectorizer.fit_transform(texts)

    train_y = []
    for text in texts:
        train_y.append(label_text(text, Indicators.GREED_LIST, Indicators.FEAR_LIST))


    clf_svm = svm.SVC(kernel='linear')
    clf_svm.fit(train_x_vectors, train_y)


    # Predi칞칚o
    news_texts = [clean_text(c + " " + t) for c, t in zip(contents, titles)]
    news_vectors = vectorizer.transform(news_texts)
    predictions = clf_svm.predict(news_vectors)

    # Contagem
    from collections import Counter
    counts = Counter(predictions)

    print("\nClassifica칞칚o das not칤cias:")
    for key, value in counts.items():
        print(f"{key}: {value}")

    # Veredito final
    fear = counts.get(Indicators.FEAR, 0)
    greed = counts.get(Indicators.GREED, 0)
    neutro = counts.get(Indicators.NEUTRAL, 0)

    if (greed > fear) and neutro < greed:
        print("\n游릭 VEREDITO FINAL: O mercado est치 OTIMISTA.")
    elif (fear > greed) and neutro < fear:
        print("\n游댮 VEREDITO FINAL: O mercado est치 com MEDO.")
    else:
        print("\n游리 VEREDITO FINAL: O mercado est치 NEUTRO.")
    